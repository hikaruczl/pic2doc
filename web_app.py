"""
Advanced OCR Webç•Œé¢ - åŸºäºGradio
æä¾›å‹å¥½çš„å›¾å½¢ç•Œé¢ç”¨äºæ•°å­¦é—®é¢˜å›¾åƒè½¬Wordæ–‡æ¡£
"""

import os
import gradio as gr
from pathlib import Path
from datetime import datetime
import yaml
from dotenv import load_dotenv

from src.main import AdvancedOCR
from src.formula_converter import FormulaConverter

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# åŠ è½½é…ç½®
with open('config/config.yaml', 'r', encoding='utf-8') as f:
    config = yaml.safe_load(f)

# åˆå§‹åŒ–OCRç³»ç»Ÿ
ocr = AdvancedOCR()
formula_converter = FormulaConverter(config)


def process_image(image_file, llm_provider, include_image, image_quality):
    """
    å¤„ç†ä¸Šä¼ çš„å›¾åƒ
    
    Args:
        image_file: ä¸Šä¼ çš„å›¾åƒæ–‡ä»¶
        llm_provider: é€‰æ‹©çš„LLMæä¾›å•†
        include_image: æ˜¯å¦åœ¨Wordä¸­åŒ…å«åŸå§‹å›¾åƒ
        image_quality: å›¾åƒè´¨é‡
        
    Returns:
        (è¾“å‡ºæ–‡ä»¶è·¯å¾„, å¤„ç†ç»“æœä¿¡æ¯, å…¬å¼ç»Ÿè®¡)
    """
    try:
        if image_file is None:
            return None, "âŒ è¯·ä¸Šä¼ å›¾åƒæ–‡ä»¶", ""
        
        # æ›´æ–°é…ç½®
        ocr.config['llm']['primary_provider'] = llm_provider.lower()
        ocr.config['document']['include_original_image'] = include_image
        ocr.config['image']['quality'] = image_quality
        
        # é‡æ–°åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        from src.llm_client import LLMClient
        from src.image_processor import ImageProcessor
        ocr.llm_client = LLMClient(ocr.config, ocr.image_processor)
        
        # å¤„ç†å›¾åƒ
        result = ocr.process_image(image_file.name)
        
        if result['success']:
            # å‡†å¤‡ç»“æœä¿¡æ¯
            stats = result['statistics']
            info = f"""
âœ… **å¤„ç†æˆåŠŸ!**

ğŸ“Š **ç»Ÿè®¡ä¿¡æ¯:**
- æ€»å…¬å¼æ•°: {stats['total_formulas']}
- æ˜¾ç¤ºå…¬å¼: {stats['display_formulas']}
- è¡Œå†…å…¬å¼: {stats['inline_formulas']}
- å…ƒç´ æ•°é‡: {result['elements_count']}

ğŸ¤– **ä½¿ç”¨æ¨¡å‹:**
- æä¾›å•†: {result['analysis']['provider']}
- æ¨¡å‹: {result['analysis']['model']}

ğŸ“„ **è¾“å‡ºæ–‡ä»¶:** {result['output_path']}
"""
            
            # å‡†å¤‡å…¬å¼åˆ—è¡¨
            formulas_text = "**è¯†åˆ«çš„å…¬å¼:**\n\n"
            for idx, (formula_type, latex) in enumerate(stats['formulas'][:10], 1):
                formulas_text += f"{idx}. [{formula_type}] `{latex}`\n"
            
            if len(stats['formulas']) > 10:
                formulas_text += f"\n... è¿˜æœ‰ {len(stats['formulas']) - 10} ä¸ªå…¬å¼"
            
            return result['output_path'], info, formulas_text
        else:
            return None, f"âŒ å¤„ç†å¤±è´¥: {result['error']}", ""
            
    except Exception as e:
        return None, f"âŒ å‘ç”Ÿé”™è¯¯: {str(e)}", ""


def batch_process(files, llm_provider):
    """
    æ‰¹é‡å¤„ç†å¤šä¸ªå›¾åƒ
    
    Args:
        files: ä¸Šä¼ çš„æ–‡ä»¶åˆ—è¡¨
        llm_provider: é€‰æ‹©çš„LLMæä¾›å•†
        
    Returns:
        å¤„ç†ç»“æœæ‘˜è¦
    """
    try:
        if not files:
            return "âŒ è¯·ä¸Šä¼ è‡³å°‘ä¸€ä¸ªæ–‡ä»¶"
        
        # æ›´æ–°é…ç½®
        ocr.config['llm']['primary_provider'] = llm_provider.lower()
        
        # é‡æ–°åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        from src.llm_client import LLMClient
        ocr.llm_client = LLMClient(ocr.config, ocr.image_processor)
        
        # æ‰¹é‡å¤„ç†
        file_paths = [f.name for f in files]
        results = ocr.process_batch(file_paths)
        
        # ç»Ÿè®¡ç»“æœ
        success_count = sum(1 for r in results if r['success'])
        total_formulas = sum(r.get('statistics', {}).get('total_formulas', 0) 
                           for r in results if r['success'])
        
        # å‡†å¤‡ç»“æœä¿¡æ¯
        summary = f"""
âœ… **æ‰¹é‡å¤„ç†å®Œæˆ!**

ğŸ“Š **å¤„ç†ç»Ÿè®¡:**
- æ€»æ–‡ä»¶æ•°: {len(results)}
- æˆåŠŸ: {success_count}
- å¤±è´¥: {len(results) - success_count}
- æ€»å…¬å¼æ•°: {total_formulas}

ğŸ“„ **å¤„ç†ç»“æœ:**
"""
        
        for idx, result in enumerate(results, 1):
            if result['success']:
                summary += f"\n{idx}. âœ… {Path(file_paths[idx-1]).name} - {result['statistics']['total_formulas']} ä¸ªå…¬å¼"
            else:
                summary += f"\n{idx}. âŒ {Path(file_paths[idx-1]).name} - {result['error']}"
        
        return summary
        
    except Exception as e:
        return f"âŒ æ‰¹é‡å¤„ç†å¤±è´¥: {str(e)}"


def get_model_info(provider):
    """è·å–æ¨¡å‹ä¿¡æ¯"""
    model_info = {
        "OpenAI": {
            "æ¨¡å‹": "GPT-4 Vision",
            "å‡†ç¡®ç‡": "95%",
            "æˆæœ¬": "$10-50/1Kå›¾",
            "é€Ÿåº¦": "10-20ç§’",
            "æ¨è": "é«˜ç²¾åº¦åœºæ™¯"
        },
        "Anthropic": {
            "æ¨¡å‹": "Claude 3 Sonnet",
            "å‡†ç¡®ç‡": "90%",
            "æˆæœ¬": "$3-8/1Kå›¾",
            "é€Ÿåº¦": "5-12ç§’",
            "æ¨è": "å¹³è¡¡æ€§ä»·æ¯” â­æ¨è"
        },
        "Gemini": {
            "æ¨¡å‹": "Gemini 1.5 Flash",
            "å‡†ç¡®ç‡": "88%",
            "æˆæœ¬": "$0.35-1.05/1Kå›¾",
            "é€Ÿåº¦": "4-10ç§’",
            "æ¨è": "æ€§ä»·æ¯”ä¹‹ç‹ â­â­æ¨è"
        },
        "Qwen": {
            "æ¨¡å‹": "Qwen-VL-Plus",
            "å‡†ç¡®ç‡": "89%",
            "æˆæœ¬": "$1.4-2.8/1Kå›¾",
            "é€Ÿåº¦": "6-12ç§’",
            "æ¨è": "å›½å†…ç”¨æˆ·ä¼˜é€‰"
        }
    }
    
    info = model_info.get(provider, {})
    if info:
        return f"""
**{provider} æ¨¡å‹ä¿¡æ¯:**

- æ¨¡å‹: {info['æ¨¡å‹']}
- å‡†ç¡®ç‡: {info['å‡†ç¡®ç‡']}
- æˆæœ¬: {info['æˆæœ¬']}
- å“åº”é€Ÿåº¦: {info['é€Ÿåº¦']}
- æ¨èåœºæ™¯: {info['æ¨è']}
"""
    return "è¯·é€‰æ‹©LLMæä¾›å•†"


# åˆ›å»ºGradioç•Œé¢
with gr.Blocks(title="Advanced OCR - æ•°å­¦é—®é¢˜å›¾åƒè½¬Word", theme=gr.themes.Soft()) as demo:
    gr.Markdown("""
    # ğŸ“ Advanced OCR - æ•°å­¦é—®é¢˜å›¾åƒè½¬Wordæ–‡æ¡£
    
    å°†åŒ…å«æ•°å­¦å…¬å¼çš„å›¾åƒè½¬æ¢ä¸ºå¯ç¼–è¾‘çš„Wordæ–‡æ¡£ï¼Œæ”¯æŒå¤šç§å¤šæ¨¡æ€LLMã€‚
    """)
    
    with gr.Tabs():
        # å•å›¾åƒå¤„ç†æ ‡ç­¾é¡µ
        with gr.TabItem("ğŸ“„ å•å›¾åƒå¤„ç†"):
            with gr.Row():
                with gr.Column(scale=1):
                    gr.Markdown("### ä¸Šä¼ å›¾åƒ")
                    image_input = gr.File(
                        label="é€‰æ‹©å›¾åƒæ–‡ä»¶",
                        file_types=[".png", ".jpg", ".jpeg", ".pdf"],
                        type="filepath"
                    )
                    
                    gr.Markdown("### é…ç½®é€‰é¡¹")
                    llm_provider = gr.Dropdown(
                        choices=["OpenAI", "Anthropic", "Gemini", "Qwen"],
                        value="Gemini",
                        label="LLMæä¾›å•†",
                        info="é€‰æ‹©ç”¨äºå›¾åƒåˆ†æçš„AIæ¨¡å‹"
                    )
                    
                    include_image = gr.Checkbox(
                        value=True,
                        label="åœ¨Wordä¸­åŒ…å«åŸå§‹å›¾åƒ"
                    )
                    
                    image_quality = gr.Slider(
                        minimum=70,
                        maximum=100,
                        value=95,
                        step=5,
                        label="å›¾åƒè´¨é‡",
                        info="å½±å“è¾“å‡ºæ–‡ä»¶å¤§å°"
                    )
                    
                    process_btn = gr.Button("ğŸš€ å¼€å§‹å¤„ç†", variant="primary", size="lg")
                
                with gr.Column(scale=1):
                    gr.Markdown("### æ¨¡å‹ä¿¡æ¯")
                    model_info_display = gr.Markdown(get_model_info("Gemini"))
                    
                    gr.Markdown("### å¤„ç†ç»“æœ")
                    result_info = gr.Markdown()
                    
                    gr.Markdown("### è¯†åˆ«çš„å…¬å¼")
                    formulas_display = gr.Markdown()
                    
                    output_file = gr.File(label="ä¸‹è½½Wordæ–‡æ¡£")
            
            # æ›´æ–°æ¨¡å‹ä¿¡æ¯
            llm_provider.change(
                fn=get_model_info,
                inputs=[llm_provider],
                outputs=[model_info_display]
            )
            
            # å¤„ç†æŒ‰é’®ç‚¹å‡»
            process_btn.click(
                fn=process_image,
                inputs=[image_input, llm_provider, include_image, image_quality],
                outputs=[output_file, result_info, formulas_display]
            )
        
        # æ‰¹é‡å¤„ç†æ ‡ç­¾é¡µ
        with gr.TabItem("ğŸ“š æ‰¹é‡å¤„ç†"):
            with gr.Row():
                with gr.Column():
                    gr.Markdown("### ä¸Šä¼ å¤šä¸ªå›¾åƒ")
                    batch_files = gr.File(
                        label="é€‰æ‹©å¤šä¸ªå›¾åƒæ–‡ä»¶",
                        file_count="multiple",
                        file_types=[".png", ".jpg", ".jpeg", ".pdf"]
                    )
                    
                    batch_llm_provider = gr.Dropdown(
                        choices=["OpenAI", "Anthropic", "Gemini", "Qwen"],
                        value="Gemini",
                        label="LLMæä¾›å•†"
                    )
                    
                    batch_process_btn = gr.Button("ğŸš€ æ‰¹é‡å¤„ç†", variant="primary", size="lg")
                
                with gr.Column():
                    gr.Markdown("### æ‰¹é‡å¤„ç†ç»“æœ")
                    batch_result = gr.Markdown()
            
            batch_process_btn.click(
                fn=batch_process,
                inputs=[batch_files, batch_llm_provider],
                outputs=[batch_result]
            )
        
        # å¸®åŠ©æ ‡ç­¾é¡µ
        with gr.TabItem("â“ å¸®åŠ©"):
            gr.Markdown("""
            ## ä½¿ç”¨è¯´æ˜
            
            ### 1. å‡†å¤‡å·¥ä½œ
            - ç¡®ä¿å·²é…ç½®APIå¯†é’¥ (åœ¨ `.env` æ–‡ä»¶ä¸­)
            - å‡†å¤‡åŒ…å«æ•°å­¦é—®é¢˜çš„å›¾åƒæ–‡ä»¶
            
            ### 2. å•å›¾åƒå¤„ç†
            1. ä¸Šä¼ å›¾åƒæ–‡ä»¶ (æ”¯æŒ PNG, JPG, PDF)
            2. é€‰æ‹©LLMæä¾›å•†
            3. é…ç½®é€‰é¡¹ (å¯é€‰)
            4. ç‚¹å‡»"å¼€å§‹å¤„ç†"
            5. ç­‰å¾…å¤„ç†å®Œæˆ
            6. ä¸‹è½½ç”Ÿæˆçš„Wordæ–‡æ¡£
            
            ### 3. æ‰¹é‡å¤„ç†
            1. ä¸Šä¼ å¤šä¸ªå›¾åƒæ–‡ä»¶
            2. é€‰æ‹©LLMæä¾›å•†
            3. ç‚¹å‡»"æ‰¹é‡å¤„ç†"
            4. æŸ¥çœ‹å¤„ç†ç»“æœ
            5. åœ¨ `output/` ç›®å½•æŸ¥æ‰¾ç”Ÿæˆçš„æ–‡æ¡£
            
            ### 4. LLMæä¾›å•†é€‰æ‹©
            - **Gemini**: æ€§ä»·æ¯”æœ€é«˜,æ¨èæ—¥å¸¸ä½¿ç”¨
            - **Anthropic**: å¹³è¡¡å‡†ç¡®ç‡å’Œæˆæœ¬
            - **OpenAI**: æœ€é«˜å‡†ç¡®ç‡,é€‚åˆé«˜è¦æ±‚åœºæ™¯
            - **Qwen**: å›½å†…ç”¨æˆ·ä¼˜é€‰,ä¸­æ–‡æ”¯æŒå¥½
            
            ### 5. æ³¨æ„äº‹é¡¹
            - å›¾åƒè´¨é‡è¶Šé«˜,è¯†åˆ«å‡†ç¡®ç‡è¶Šé«˜
            - å¤æ‚å…¬å¼å¯èƒ½éœ€è¦æ‰‹åŠ¨è°ƒæ•´
            - APIè°ƒç”¨ä¼šäº§ç”Ÿè´¹ç”¨,è¯·æ³¨æ„æ§åˆ¶ä½¿ç”¨é‡
            
            ### 6. è·å–å¸®åŠ©
            - æŸ¥çœ‹ [README.md](README.md) äº†è§£è¯¦ç»†ä¿¡æ¯
            - æŸ¥çœ‹ [MODEL_COMPARISON.md](MODEL_COMPARISON.md) äº†è§£æ¨¡å‹å¯¹æ¯”
            - é‡åˆ°é—®é¢˜è¯·æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶: `logs/`
            """)
    
    gr.Markdown("""
    ---
    ğŸ’¡ **æç¤º**: é¦–æ¬¡ä½¿ç”¨è¯·ç¡®ä¿å·²åœ¨ `.env` æ–‡ä»¶ä¸­é…ç½®ç›¸åº”çš„APIå¯†é’¥
    
    ğŸ“š **æ–‡æ¡£**: [README](README.md) | [å¿«é€Ÿå¼€å§‹](QUICKSTART.md) | [æ¨¡å‹å¯¹æ¯”](MODEL_COMPARISON.md)
    """)


if __name__ == "__main__":
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_error=True
    )

